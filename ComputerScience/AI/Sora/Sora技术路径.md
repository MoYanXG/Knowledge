# Sora能力边界探索
## 优势

拓展至60秒高清视频生成

保持人物与场景的高度一致性

具有强大的视频融合能力

同一场景下的多镜头生成能力

可生成动态摄像机运动的镜头，且保持其他元素可移动

支持任意分辨率

强大的文生图能力，更为真实

视频可以向前与向后拓展

生成游戏场景视频

## 限制

物理规则的理解仍旧有限

# Sora模型训练过程

将原始数据切分，通过特定编码器压缩为低维空间表示；后将处理过的数据基于Diffusion Transformer 来完成文本与图像的映射；DiT 生成的低维空间表示，使用特定解码器恢复为视频数据


统一表示不同类型的视频数据(将视频的帧图像分割成包含时间序列和空间序列的Patch，再转换成一维向量)

# Sora关键技术拆解
ViT：将Transformer结构应用于图像
	图像划分为多个 patch 后，将二维 patch 转换为一维向量作为 Transformer 的输入
	(把图像划分为多个等大小的图像碎块，再把碎块分割成一维向量，喂给模型)


视频的处置：对时间维度的处理，将时间维度信息与图像维度信息匹配
	摊平法：把视频分为n个图片，对每个图片逐个扫描学习
	切块法：输入的视频对画面进行固定化切分(切成块)，然后再对时间轴进行片化切分(把块切成更小的等大的块)


Diffusion Transformer（DiT）
	此中道理深奥，在下确实不懂


Diffusion Model：在数据中加入噪声，噪声会逐渐扩散并分布与数据中(符合高斯分布)，以此来对AI进行识别生成训练

# 从Sora技术洞见到视觉生成技术新生态探索

数据量够大，描述够精确，同一模型下可能会导致不同的结果
	那么能否在指定数据量下，探索最优模型？
	堆数据量的效果在什么范围内会达到边际效应？

智能人一定会画电子画吗？
会画电子画一定是智能人吗？

一分钟也许是Sora 的极限

Sora 的视频拼接能力也许很差劲
